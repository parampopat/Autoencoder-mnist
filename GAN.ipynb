{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Dense, Input, Lambda, BatchNormalization \n",
    "from keras.models import Model\n",
    "from keras.optimizers import adadelta, adam \n",
    "from keras.regularizers import l1\n",
    "import pydot\n",
    "import matplotlib.pyplot as plt \n",
    "import keras.backend as K\n",
    "from keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_discrm(input_size):\n",
    "    \n",
    "    x_in=Input(shape=(input_size, ))\n",
    "    X=Dense(512,activation='relu')(x_in)\n",
    "    X=Dense(256,activation='relu')(X)\n",
    "    y=Dense(1,activation='sigmoid')(X)\n",
    "    \n",
    "    \n",
    "    discriminator = Model(inputs=x_in, outputs = y) \n",
    "    \n",
    "    discriminator.compile(optimizer='adam',loss='binary_crossentropy')\n",
    "    \n",
    "    return discriminator\n",
    "    \n",
    "\n",
    "discriminator= build_discrm(input_size=784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_27 (InputLayer)        (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 131,585\n",
      "Non-trainable params: 401,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gen(embed_size):\n",
    "    \n",
    "    x_in = Input(shape=(embed_size,))\n",
    "    X=Dense(128,activation='relu')(x_in)\n",
    "    X=Dense(256,activation='relu')(X)\n",
    "    Y=Dense(784,activation='sigmoid')(X)\n",
    "    generator= Model(inputs=x_in,outputs= Y)\n",
    "    generator.compile(optimizer='adam',loss='binary_crossentropy')\n",
    "    return generator\n",
    "\n",
    "generator=build_gen(embed_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_28 (InputLayer)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 784)               201488    \n",
      "=================================================================\n",
      "Total params: 251,024\n",
      "Trainable params: 251,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adversarial(input_size,embed_size,generator, discriminator):\n",
    "    \n",
    "    \n",
    "    z_in= Input(shape=(embed_size,))\n",
    "    x_gen = generator(z_in) \n",
    "    #discriminator.trainable= False    # only generator\n",
    "    #discriminator.compile(loss='binary_crossentropy',optimizer='adam')\n",
    "    y = discriminator(x_gen)\n",
    "    adversarial = Model(inputs = z_in ,outputs = y)\n",
    "    adversarial.compile(optimizer='adam', loss = 'binary_crossentropy')\n",
    "    return adversarial\n",
    "\n",
    "\n",
    "adversarial = build_adversarial(input_size=784,embed_size=128,generator=generator, discriminator=discriminator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x2017d85cdd8>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversarial.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_27 (InputLayer)        (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def model_train(x_train,x_test,batch_size,embed_size,epochs,sample_interval,generator,discriminator,adversarial):\n",
    "    \n",
    "    real = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "        noise = np.random.normal(0, 1, (batch_size, embed_size))\n",
    "        \n",
    "        gen_imgs= generator.predict(noise)\n",
    "\n",
    "        real_image_loss =discriminator.train_on_batch(x=imgs, y= real)\n",
    "        fake_image_loss = discriminator.train_on_batch(x=gen_imgs, y = fake)\n",
    "        \n",
    "        total_loss = 0.5 *np.add(real_image_loss ,fake_image_loss)\n",
    "        \n",
    "        \n",
    "        noise = np.random.normal(0, 1, (batch_size, embed_size))\n",
    "        \n",
    "        gen_loss = adversarial.train_on_batch(x= noise , y = real)\n",
    "        \n",
    "        print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, d_loss, g_loss))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, _), (X_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train/255\n",
    "X_test=X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x201033050b8>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],np.prod(X_train.shape[1:]))\n",
    "X_test = X_test.reshape(X_test.shape[0],np.prod(X_test.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_27 (InputLayer)        (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_29 (InputLayer)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "model_23 (Model)             (None, 784)               251024    \n",
      "_________________________________________________________________\n",
      "model_22 (Model)             (None, 1)                 533505    \n",
      "=================================================================\n",
      "Total params: 784,529\n",
      "Trainable params: 784,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adversarial.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 7.971192] [G loss: 0.000000]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-157-62200aab3ea1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mgen_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madversarial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnoise\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"%d [D loss: %f] [G loss: %f]\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0msample_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-157-62200aab3ea1>\u001b[0m in \u001b[0;36msample_images\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                 \u001b[0maxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcnt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m                 \u001b[0maxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[0mcnt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEfNJREFUeJzt3c9rZFWfx/H399FOC4EGBRfSreiQNqHphUzadufWduVmBLMWehP/AP8RhQn4jLiJuJRB4taNUOkSZqZFW3uchUHhoemNQv/Q4juLpCuVnCrrZKrSU6fq/YIsbuXkcvLh3E8Xt++pRGYiSWrH3/6/JyBJOhmLW5IaY3FLUmMsbklqjMUtSY2xuCWpMWOLOyL+HhH/iIibj2NCrTCXkpmUzKRkJpOrecf9MXDtlOfRoo8xl+M+xkyO+xgzOe5jzGQiY4s7M78C7j6GuTTFXEpmUjKTkplM7slpnSgirgPXAZaXl9fX1tamdeqZ1O127wCv/tWYRcvkwF3g11HfNJOSmQy3aLl0u907mflszdio2fIeES8C/56Zl2tOeuXKlbxx40bN0GZFRBf4FypzWYRMACLiv4C/mckhMymdJBNYjFwiopuZV2rG+lSJJDXG4pakxtQ8DrgNfA2sRsReRLx7+tNqwkuYyxEbGxsAa5hJn5mUzGRyNU+VbGTmc5l5JjMvZOZHj2NiDfgfczlqe3sb4D/N5JCZlMxkct4qkaTGWNyS1BiLW5IaY3FLUmMsbklqjMUtSY2xuCWpMRa3JDXG4pakxljcktQYi1uSGmNxS1JjLG5JaozFLUmNsbglqTEWtyQ1xuKWpMZY3JLUGItbkhpjcUtSYyxuSWqMxS1JjbG4JakxFrckNcbilqTGWNyS1BiLW5IaY3FLUmMsbklqTFVxR8S1iLgVEbcj4v3TnlQjzpnJUTs7OwCXzaTgWimZyQTGFndEPAF8ALwJXAI2IuLSaU9slvV6PYAXMJO+Xq/H5uYmwA+YSZ9rpWQmk6t5x30VuJ2ZP2XmQ+BT4K3TndZs63Q6AA/M5FCn02FlZQXgoZkccq2UzGRyT1aMOQ/8PHC8B7x2fFBEXAeuHxw+iIibk09vZj0NPD9wbCb7mZwDVg+OzWTf2LViJq6VA6vjh+yrKe4Y8loWL2RuAVsAEXEjM6/UTqI1EfE28OGxl80E3gBeGXh5oTOBurViJoBrhYi4UTu25lbJHkf/dbwA/HLSSc2ZPWBp4NhMXCejuFZKZjKhmuLeBS5GxEsRsQS8A3x+utOaebvAU2ZyxC5wEVgykyNcKyUzmVBNcW8BzwDfA98Bn2XmtxU/M7cy80/gNvAj8BtmMpjJZcxk0BbQo/76MZPRPzPvqn/HyCxuLR0dEPE68DvwSWZennBic8NcSmZSMpOSmUxu7DvuzPwKuPsY5tIUcymZSclMSmYyuZqnSqoMPrqzvLy8vra2Nq1Tz6Rut3sHePWvxixaJgfuAr+O+qaZlMxkuEXLpdvt3snMZ6sGZ+bYL+BF4GbFuGvArfX19Zx3wL2aXBYpk8xM4H7tWjETM0k7pQ+4lxV9nJnT+5CpY1vjhZmMMpCLDphJyetntGl+OmB/a/wUz9k6MxnuKvtPoOiQmZS8fkao+ZCpbeBrYDUi9iLi3RFDj2+Nn3dnGJ/LQmWysbEBcBbXSp+ZlMxkcjVPlWxk5nOZeSYzL2TmRyOGDtsaP8/+qMhloTLZ3t4GuO9aOWQmJTOZ3DRvlRzf8iwzGcVcSmZSMpMRplnc/a3xUzxn68xkuEfb43XITEpePyNMrbhzf8vze8CX0zrnjDs75v7cImYCJ8tlUZhJyeunNDaTR6b6Nycz84vMfHma55xh34y5PwcsXCZwglwe14RmgJmUvH5KVZmAfyxYkppjcUtSYyxuSWqMxS1JjbG4JakxFrckNcbilqTGWNyS1BiLW5IaY3FLUmMsbklqjMUtSY2xuCWpMRa3JDXG4pakxljcktQYi1uSGmNxS1JjLG5JaozFLUmNsbglqTEWtyQ1xuKWpMZY3JLUGItbkhpTVdwRcS0ibkXE7Yh4/7Qn1YhzZnLUzs4OwGUzKbhWSmYygbHFHRFPAB8AbwKXgI2IuHTaE5tlvV4P4AXMpK/X67G5uQnwA2bS51opmcnkat5xXwVuZ+ZPmfkQ+BR463SnNds6nQ7AAzM51Ol0WFlZAXhoJodcKyUzmdyTFWPOAz8PHO8Brx0fFBHXgesHhw8i4ubk05tZTwPPDxybyX4m54DVg2Mz2Td2rZiJa+XA6vgh+2qKO4a8lsULmVvAFkBE3MjMK7WTaE1EvA18eOxlM4E3gFcGXl7oTKBurZgJ4FohIm7Ujq25VbLH0X8dLwC/nHRSc2YPWBo4NhPXySiulZKZTKimuHeBixHxUkQsAe8An5/utGbeLvCUmRyxC1wElszkCNdKyUwmVFPcW8AzwPfAd8Bnmfltxc/Mrcz8E7gN/Aj8hpkMZnIZMxm0BfSov37MZPTPzLvq3zEyi1tLRwdEvA78DnySmZcnnNjcMJeSmZTMpGQmkxv7jjszvwLuPoa5NMVcSmZSMpOSmUyu5qmSKoOP7iwvL6+vra1N69Qzqdvt3gFe/asxi5bJgbvAr6O+aSYlMxlu0XLpdrt3MvPZqsGZOfYLeBG4WTHuGnBrfX095x1wryaXRcokMxO4X7tWzMRM0k7pA+5lRR9n5vQ+ZOrY1nhhJqMM5KIDZlLy+hltmp8O2N8aP8Vzts5MhrvK/hMoOmQmJa+fEWo+ZGob+BpYjYi9iHh3xNDjW+Pn3RnG57JQmWxsbACcxbXSZyYlM5lczVMlG5n5XGaeycwLmfnRiKHDtsbPsz8qclmoTLa3twHuu1YOmUnJTCY3zVslx7c8y0xGMZeSmZTMZIRpFnd/a/wUz9k6Mxnu0fZ4HTKTktfPCFMr7tzf8vwe8OW0zjnjzo65P7eImcDJclkUZlLy+imNzeSRqf7Nycz8IjNfnuY5Z9g3Y+7PAQuXCZwgl8c1oRlgJiWvn1JVJuAfC5ak5ljcktQYi1uSGmNxS1JjLG5JaozFLUmNsbglqTEWtyQ1xuKWpMZY3JLUGItbkhpjcUtSYyxuSWqMxS1JjbG4JakxFrckNcbilqTGWNyS1BiLW5IaY3FLUmMsbklqjMUtSY2xuCWpMRa3JDXG4pakxlQVd0Rci4hbEXE7It4/7Uk14pyZHLWzswNw2UwKrpWSmUxgbHFHxBPAB8CbwCVgIyIunfbEZlmv1wN4ATPp6/V6bG5uAvyAmfS5VkpmMrmad9xXgduZ+VNmPgQ+Bd463WnNtk6nA/DATA51Oh1WVlYAHprJIddKyUwm92TFmPPAzwPHe8BrxwdFxHXg+sHhg4i4Ofn0ZtbTwPMDx2ayn8k5YPXg2Ez2jV0rZuJaObA6fsi+muKOIa9l8ULmFrAFEBE3MvNK7SRaExFvAx8ee9lM4A3glYGXFzoTqFsrZgK4VoiIG7Vja26V7HH0X8cLwC8nndSc2QOWBo7NxHUyimulZCYTqinuXeBiRLwUEUvAO8DnpzutmbcLPGUmR+wCF4ElMznCtVIykwnVFPcW8AzwPfAd8FlmflvxM3MrM/8EbgM/Ar9hJoOZXMZMBm0BPeqvHzMZ/TPzrvp3jMzi1tLRARGvA78Dn2Tm5QknNjfMpWQmJTMpmcnkxr7jzsyvgLuPYS5NMZeSmZTMpGQmk6t5qqTK4KM7y8vL62tra9M69Uzqdrt3gFf/asyiZXLgLvDrqG+aSclMhlu0XLrd7p3MfLZqcGaO/QJeBG5WjLsG3FpfX895B9yryWWRMsnMBO7XrhUzMZO0U/qAe1nRx5k5vQ+ZOrY1XpjJKAO56ICZlLx+RpvmpwP2t8ZP8ZytM5PhrrL/BIoOmUnJ62eEmg+Z2ga+BlYjYi8i3h0x9PjW+Hl3hvG5LFQmGxsbAGdxrfSZSclMJlfzVMlGZj6XmWcy80JmfjRi6LCt8fPsj4pcFiqT7e1tgPuulUNmUjKTyU3zVsnxLc8yk1HMpWQmJTMZYZrF3d8aP8Vzts5Mhnu0PV6HzKTk9TPC1Io797c8vwd8Oa1zzrizY+7PLWImcLJcFoWZlLx+SmMzeWSqf3MyM7/IzJenec4Z9s2Y+3PAwmUCJ8jlcU1oBphJyeunVJUJ+MeCJak5FrckNcbilqTGWNyS1BiLW5IaY3FLUmMsbklqjMUtSY2xuCWpMRa3JDXG4pakxljcktQYi1uSGmNxS1JjLG5JaozFLUmNsbglqTEWtyQ1xuKWpMZY3JLUGItbkhpjcUtSYyxuSWqMxS1JjbG4JakxVcUdEdci4lZE3I6I9097Uo04ZyZH7ezsAFw2k4JrpWQmExhb3BHxBPAB8CZwCdiIiEunPbFZ1uv1AF7ATPp6vR6bm5sAP2Amfa6VkplMruYd91Xgdmb+lJkPgU+Bt053WrOt0+kAPDCTQ51Oh5WVFYCHZnLItVIyk8k9WTHmPPDzwPEe8NrxQRFxHbh+cPggIm5OPr2Z9TTw/MCxmexncg5YPTg2k31j14qZuFYOrI4fsq+muGPIa1m8kLkFbAFExI3MvFI7idZExNvAh8deNhN4A3hl4OWFzgTq1oqZAK4VIuJG7diaWyV7HP3X8QLwy0knNWf2gKWBYzNxnYziWimZyYRqinsXuBgRL0XEEvAO8PnpTmvm7QJPmckRu8BFYMlMjnCtlMxkQjXFvQU8A3wPfAd8lpnfVvzM3MrMP4HbwI/Ab5jJYCaXMZNBW0CP+uvHTEb/zLyr/h0js7i1dHRAxOvA78AnmXl5wonNDXMpmUnJTEpmMrmx77gz8yvg7mOYS1PMpWQmJTMpmcnkap4qqTL46M7y8vL62tratE49k7rd7h3g1b8as2iZHLgL/Drqm2ZSMpPhFi2Xbrd7JzOfrRqcmWO/gBeBmxXjrgG31tfXc94B92pyWaRMMjOB+7VrxUzMJO2UPuBeVvRxZk7vQ6aObY0XZjLKQC46YCYlr5/RpvnpgP2t8VM8Z+vMZLir7D+BokNmUvL6GaHmQ6a2ga+B1YjYi4h3Rww9vjV+3p1hfC4LlcnGxgbAWVwrfWZSMpPJ1TxVspGZz2Xmmcy8kJkfjRg6bGv8PPujIpeFymR7exvgvmvlkJmUzGRy07xVcnzLs8xkFHMpmUnJTEaYZnH3t8ZP8ZytM5PhHm2P1yEzKXn9jDC14s79Lc/vAV9O65wz7uyY+3OLmAmcLJdFYSYlr5/S2EwemerfnMzMLzLz5Wmec4Z9M+b+HLBwmcAJcnlcE5oBZlLy+ilVZQL+sWBJao7FLUmNsbglqTEWtyQ1xuKWpMZY3JLUGItbkhpjcUtSYyxuSWqMxS1JjbG4JakxFrckNcbilqTGWNyS1BiLW5IaY3FLUmMsbklqjMUtSY2xuCWpMRa3JDXG4pakxljcktQYi1uSGmNxS1JjLG5JakxVcUfEtYi4FRG3I+L9055UI86ZyVE7OzsAl82k4FopmckExhZ3RDwBfAC8CVwCNiLi0mlPbJb1ej2AFzCTvl6vx+bmJsAPmEmfa6VkJpOrecd9FbidmT9l5kPgU+Ct053WbOt0OgAPzORQp9NhZWUF4KGZHHKtlMxkck9WjDkP/DxwvAe8dnxQRFwHrh8cPoiIm5NPb2Y9DTw/cGwm+5mcA1YPjs1k39i1YiaulQOr44fsqynuGPJaFi9kbgFbABFxIzOv1E6iNRHxNvDhsZfNBN4AXhl4eaEzgbq1YiaAa4WIuFE7tuZWyR5H/3W8APxy0knNmT1gaeDYTFwno7hWSmYyoZri3gUuRsRLEbEEvAN8frrTmnm7wFNmcsQucBFYMpMjXCslM5nQ2FslmflnRLwHfAk8Afw9M78d82Nb05jcrDrI5F8xk76BdfJvwHeYCfB/WitmMtzc58IJfsfILG4tSZJmmDsnJakxFrckNWaqxb0IW+Mj4u8R8Y/aZ0oXIRMwl2HMpGQmpZNmAkBmTuWL/f9k+G/gn9h/1Oc/gEvTOv+sfAGvA/8M3DQTczETM3mcmTz6muY77oXYGp+ZXwF3K4cvRCZgLsOYSclMSifMBJjurZJhW+PPT/H8LTKT4cylZCYlMxlhmsVdtTV+wZjJcOZSMpOSmYwwzeJ2y3PJTIYzl5KZlMxkhGkWt1vjS2YynLmUzKRkJiNMrbgz80/g0db474DPcvw21uZExDbwNbAaEXsR8e6osYuSCZjLMGZSMpPSSTLp/8zB4yiSpEa4c1KSGmNxS1JjLG5JaozFLUmNsbglqTEWtyQ1xuKWpMb8L+63+Pv3uCG5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_size=256\n",
    "embed_size=128\n",
    "epochs = 20\n",
    "\n",
    "def sample_images(epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, embed_size))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        #gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "        real = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "        noise = np.random.normal(0, 1, (batch_size, embed_size))\n",
    "        gen_imgs= generator.predict(noise)\n",
    "        discriminator.trainable=True\n",
    "        discriminator.compile(optimizer='adam',loss='binary_crossentropy')\n",
    "        real_image_loss =discriminator.train_on_batch(x=imgs, y= real)\n",
    "        fake_image_loss = discriminator.train_on_batch(x=gen_imgs, y = fake)\n",
    "        total_loss = 0.5 *np.add(real_image_loss ,fake_image_loss)\n",
    "        noise = np.random.normal(0, 1, (batch_size, embed_size))\n",
    "        discriminator.trainable=False\n",
    "        discriminator.compile(optimizer='adam',loss='binary_crossentropy')\n",
    "        gen_loss = adversarial.train_on_batch(x= noise , y = real)\n",
    "        print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, total_loss, gen_loss))\n",
    "        sample_images(epoch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_imgs=generator.predict(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 784)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_image_loss =discriminator.train_on_batch(x=imgs, y= real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55012965"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_image_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_image_loss = discriminator.train_on_batch(x=gen_imgs, y = fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6773343"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_image_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial.layers[2].trainable=False\n",
    "adversarial.compile(optimizer='adam',loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_26 (InputLayer)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "model_20 (Model)             (None, 784)               251024    \n",
      "_________________________________________________________________\n",
      "model_19 (Model)             (None, 1)                 533505    \n",
      "=================================================================\n",
      "Total params: 784,529\n",
      "Trainable params: 251,024\n",
      "Non-trainable params: 533,505\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adversarial.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,067,010\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 533,505\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(optimizer='adam',loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 0\n",
      "Non-trainable params: 533,505\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_26 (InputLayer)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "model_20 (Model)             (None, 784)               251024    \n",
      "_________________________________________________________________\n",
      "model_19 (Model)             (None, 1)                 533505    \n",
      "=================================================================\n",
      "Total params: 784,529\n",
      "Trainable params: 251,024\n",
      "Non-trainable params: 533,505\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adversarial.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable=False\n",
    "discriminator.compile(optimizer='adam',loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_26 (InputLayer)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "model_20 (Model)             (None, 784)               251024    \n",
      "_________________________________________________________________\n",
      "model_19 (Model)             (None, 1)                 533505    \n",
      "=================================================================\n",
      "Total params: 784,529\n",
      "Trainable params: 251,024\n",
      "Non-trainable params: 533,505\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adversarial.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.normal(0, 1, (batch_size, embed_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nosie' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-9bd2a339d678>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnosie\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshpae\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'nosie' is not defined"
     ]
    }
   ],
   "source": [
    "nosie.shpae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 128)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_loss = adversarial.train_on_batch(x= noise , y = real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18289107"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
